---
title: "Lab_10_Individual_Section_Luke"
author: "Luke Fanning"
date: "11/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(tidyverse)
answers <- read_csv("Answers_trunc.csv")
questions <- read_csv("Questions_trunc.csv")
colnames(answers)
colnames(questions)
str(answers)
str(questions)

```

## Luke Fanning Individual Section

### Question regarding the Questions table:
**Does a question with a shorter body length (in terms of total characters) typically get a higher score than a question with a longer body length?**

This question is interesting to me as it analyzes something I've always been curious about. Visually, I'm personally turned off from reading a question on stackoverflow when the body seems really convuluted and long, as it makes me believe that the question is overly specific and not relatable to whatever assignment I'm currently working on. Therefore, I'd like to see if my personal taste is indicative of a larger trend for questions as a whole, or whether most people are willing to stick out a meatier body in hopes that the subject will be more interesting and/or more relatable to a common question or topic on the site, inidcated by the score the question recieved. 

```{r}
questions <- questions %>% mutate(letters_body = str_count(Body, regex("[a-z]", ignore_case = T)))
ggplot(data = questions, mapping = aes(x = letters_body, y = Score)) + geom_jitter() + xlim(c(0, 3000)) + labs(title = "Question Body Length vs. Score", x = "Number of letters in body of question", y = "Score")
ggplot(data = questions, mapping = aes(x = letters_body, y = Score)) + geom_jitter() + xlim(c(0, 500))+ labs(title = "Question Body Length vs. Score", x = "Number of letters in body of question", y = "Score")
```
At first, simply by looking at a plot of length in terms of number of characters vs. score, there does seem to be a trend towards what I would subjectively call medium length bodies, where the body is not so short that it is impossible to tell what the question is regarding, but not too long that it is unattractive to the reader. This appears to fall somewhere in the 0 - 1000 character length range, which, considering that the average word in the english language is about five characters long, makes sense, as about 100-200 words seems appropriate for fully elucidating a question topic without overexplaining or boring the audience. However, while there is an indication of a trend in the data, I wanted to check one small thing regarding the letters_body column itself, as seen in the plot below.

```{r}
ggplot(data = questions, mapping = aes(x = letters_body)) + geom_density() + labs(title = "Question Body Length vs. Density", x = "Number of letters in body of question", y = "Density of question body length")
ggplot(data = questions, mapping = aes(x = letters_body)) + geom_density() + xlim(c(0, 1000))+ labs(title = "Question Body Length vs. Density", x = "Number of letters in body of question", y = "Density of question body length")

```
As seen in the plot above, the relationship that was described above may be virtually obselete, as while there may be some trend towards a medium length question body based off of score, this is more likely just due to the fact that an overwhelming majority of bodies for questions submitted to the stackoverflow topic "python questions" have a length between 0 - 1000 characters. However, this does answer my ultimate question regarding question length, as it seems that most people also feel like in order for a question to be worthwhile, the body of the question must be kept relatively brief in order to gain the attention of the reader and answerer.

### Question regarding the answers table:
**Does the usage of the word python in the response to a question affect the score of that response?**
This question interests me because theoretically, there should be no discernable difference between responses that mention the relevant programming language and questions that don't, as these questions and responses are all from the python questions section of stackoverflow. However, as seen below, it does seem as though there is a correlation betwen higher rated responses and literally stating the word python somewhere in the response.This correlation may be due to higher quality responses often working to teach the user how to do a specific aspect of programming in the language rather than simply responding with the problem for their specific section of code that they are having issues with.  


```{r}
answers <- answers %>% mutate(python_true = str_detect(Body, regex("python", ignore_case = T)))
ggplot(data = answers, mapping = aes(x = python_true, y = Score)) + geom_jitter() + labs(title = "Usage of the word python(true or false) vs. Score", x = "Usage of the word python in the response (true or false)", y = "Score")
```

